{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gurliv24/UTS_ML_13476256/blob/master/Assignment%202%20Report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Z08jR3EbK1T",
        "colab_type": "text"
      },
      "source": [
        "<figure>\n",
        "<center>\n",
        "<img src= 'https://drive.google.com/uc?id=1K5YOfDVf6Fq7cNE11ku_dXjjDYyaKhC6'width=\"200\" height=\"100\"/>\n",
        "</center>\n",
        "</figure>\n",
        "\n",
        "<center>\n",
        "<font size=\"5\">Machine Learning </font>\n",
        "<br>\n",
        "  <br>\n",
        "Spring 2019\n",
        "  <br>\n",
        "  <br>\n",
        "\n",
        "\n",
        "**Assessment 2**\n",
        "<br>\n",
        "  <br>\n",
        "  \n",
        "\n",
        "<font size=\"4\">**Heart Disease Prediction & Factors that Indicate the Onset of Heart Disease**</font>\n",
        "\n",
        "<br>\n",
        "  <br>\n",
        "  \n",
        "  <U>Presented by</U>\n",
        "\n",
        "Gurliv Pal Singh [13476256]\n",
        "\n",
        "  </center>\n",
        "  \n",
        "<p style=\"page-break-after: always;\">&nbsp;</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Y1E0RS5QTeZ",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "# INTRODUCTION\n",
        "\n",
        "This is a machine learning project is intended to find out whether a person is suffering from heart diseases or not. If a person with heart disease can be predicted with high accuracy, then the people can be warned about it. They get a warning and a chance to change their lifestyles to prevent it from happening or becoming anything serious. The dataset is taken from Kaggle and machine learning algorithms are used to predict whether a person has heart disease or not.\n",
        "\n",
        "Nowadays, number of people with heart diseases is increasing rapidly due to the unhealthy diet – junk food and lack of exercise. Earlier it was a myth that only old or aged people are prone to heart diseases, but now there is a lot of cases of young people having heart disease as well. Coronary artery disease is one of the most dangerous heart diseases. It has affected more than 13 million people in in America. Sometimes the symptoms of heart diseases are not easily noticeable, and people tend to ignore them. Unfortunately, the heart disease is detected in the later stages when it becomes extremely serious. \n",
        "\n",
        "Hence, there is a great need of a technology that can predict that a person has a heart disease or not. By building a machine learning model we can help the people by letting them know whether they are suffering from a heart disease or susceptible to it.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3h8OnIkRNVe",
        "colab_type": "text"
      },
      "source": [
        "# EXPLORATION\n",
        "\n",
        "## Dataset\n",
        "There are 76 attributes in this dataset. Although, only a subset 14 of the attributes is used and referred in all the published works. Machine learning scholars have used only the Cleveland database till now. The attribute ‘goal’ denotes that a person is suffering from a heart disease. It is integer valued from 0 (no presence) to 4. The value of this attribute is integers o to 4, where 0 means no presence. The values 1,2,3 and 4 are the levels of presence of a heart disease in a patient. The value 0 indicates that there is no heart disease present.\n",
        "\n",
        "The names and social security number of the patients are removed and replaced by dummy values.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knHDfRo1RmCW",
        "colab_type": "text"
      },
      "source": [
        "## Libraries imported:\n",
        "\n",
        "We should import all the necessary libraries. Firstly, numpy is used to work with arrays, pandas to work with csv files have been used. Matplotlib has a sub package named pyplot, which will be used for data visualization. Styling is done to the plots by using rcParams and colors are added by using rainbow. sklearn library is used to implement the data processing and models of machine learning. Warnings library is to avoid all warnings. Train_test_split for splitting the dataset into training and testing data. StandardScaler to scale the features due to which the model performs better.\n",
        "\n",
        "##Attribute Information:\n",
        "\n",
        "Only 14 attributes used out of the 76 available:\n",
        "1. age – shows the age of patient in years.  \n",
        "2. sex – denotes that a person is male or female.\n",
        "3.  cp – reflects the type of chest pain.\n",
        "4. trestbps – shows the resting blood pressure (in mm Hg). \n",
        "5. chol – denotes the serum cholesterol in mg/dl.\n",
        "6. fbs – Attribute whose value is 1 if fasting blood sugar is greater than 120 mg/dl, otherwise 0.\t  \n",
        "7. restecg – shows resting electrocardiographic results.  \n",
        "8. thalach – denotes the maximum heart rate reached. \n",
        "9. exang – shows exercise induced angina with values 1 for yes and 0 for no. \n",
        "10. oldpeak – represents ST depression induced by exercise relative to rest. \n",
        "11. slope – denotes the slope of the peak exercise ST segment.\n",
        "12. ca – it tells the number of major vessels from 0 to 3 colored by fluoroscopy.\n",
        "13. thal – Attribute in which 3 = normal; 6 = fixed defect; 7 = reversable defect. \n",
        "14. num – it is the predicted attribute for the diagnosis of heart disease.\n",
        "\n",
        "\n",
        "\n",
        "<figure>\n",
        "<center>\n",
        "<img src= 'https://drive.google.com/uc?id=1VJFkWzo0jLmVf1qtsnDOuxIvakoL1oqx'/>\n",
        "<figcaption> Figure 1. Data set</figcaption></center>\n",
        "</figure>\n",
        "\n",
        "<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSvkGb-cYNXj",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# METHODOLOGY\n",
        "\n",
        "## Correlation matrix\n",
        "\n",
        "\n",
        "is used to analyze the relations between the columns. The size of the figure is kept as 12x8 with the help of rcParams. The correlation matrix is shown by using pyplot. Colorbar function displays the colorbar for the matrix.\n",
        "You can see in the correlation matrix below that there is no attribute that has high correlation with our target value. \n",
        "\n",
        "\n",
        "\n",
        "<figure>\n",
        "<center>\n",
        "<img src= 'https://drive.google.com/uc?id=11PFBKP0LZaCNSgiZ3Kg9RW9OytOcq7Oz' />\n",
        "<figcaption>  </figcaption></center>\n",
        "</figure>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##Histogram \n",
        "\n",
        "It represents that the attributes are distributed along various ranges. Therefore, we can see that scaling is required. There are a lot of categorical variables that we need to deal with before implementing machine learning.\t\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<figure>\n",
        "<center>\n",
        "<img src= 'https://drive.google.com/uc?id=17paPLLAMEs0hu7KJ8j85JyL0rZzF6ONr'/>\n",
        "<figcaption> </figcaption></center>\n",
        "</figure>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##Bar Plot\n",
        "In the bar plot for target class, it is visible that the classes are well balanced and ready for data processing.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<figure>\n",
        "<center>\n",
        "<img src= 'https://drive.google.com/uc?id=1iiPAm1n2gB6mqQR81JaJE0js1-1Go8O5'/>\n",
        "<figcaption> </figcaption></center>\n",
        "</figure>\n",
        "\n",
        "##Data Processing:\n",
        "Categorical attribute should be broken into columns with 1’s and o’s. This can be done by using get_dummies() function. Subsequently, we need to scale the data and that can be done by using fit_transform() funciton. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEYk6psBaxuS",
        "colab_type": "text"
      },
      "source": [
        "# EVALUATION\n",
        "\n",
        "The data set is split into 67% and 33%, training data and testing data respectively. Four algorithms are used, and final models are compared after tweaking and tuning various parameters. \n",
        "##K-Neighbor classifier: \n",
        "The classifier looks for the number of nearest neighbors to a given data point and whichever class is in majority is assigned to this data point. Number of neighbors can be changed and below is the line graph which shows the test results for each number of neighbors (1-20). The best result is 87% and it was achieved when the number of neighbors is 8\n",
        "\n",
        " \n",
        "<figure>\n",
        "<center>\n",
        "<img src= 'https://drive.google.com/uc?id=1CWXwKC_WWVHCirKGGd9S5LdTd1Qtbtay'/>\n",
        "</center>\n",
        "</figure>\n",
        "\n",
        "\n",
        "##Support Vector Machine:\n",
        "In this a hyperplane is formed to separate the classes from each other by fine-tuning the distance between the data points and the hyperplane. Hyperplane is decided by the type of kernels. Below you can see that 4 kernels are used – rbf, sigmoid, poly and linear. The best result was 83% and was achieved by using linear kernel.\n",
        "\n",
        "<figure>\n",
        "<center>\n",
        "<img src= 'https://drive.google.com/uc?id=1Y3plGA2J6qMqKX_E1ljZX1P2-ts4jK_a'/>\n",
        "</center>\n",
        "</figure>\n",
        "\n",
        "\n",
        "##Decision Tree: \n",
        "\n",
        "This classifier creates a decision tree according to which a class value is allotted to every data point. The maximum number of features that are considered can be adjusted. In the line graph below, the best result is 79% and it is achieved when the value of maximum features to be selected is 2, 4 or 18.\n",
        "\n",
        "<figure>\n",
        "<center>\n",
        "<img src= 'https://drive.google.com/uc?id=1KU1oF6EL7Fo6ub3tYAgdUF-KsYcczRjd'/>\n",
        "</center>\n",
        "</figure>\n",
        "\n",
        "##Random Forest:\n",
        "In this classifier, a forest of tree is created by a random selection of attributes from the total attributes. The number of trees that will be used to predict a class can be adjusted.  In the below bar graph, the best result is 84% and it was achieved when the number of trees was 500 or 100.\n",
        "\n",
        "\n",
        "<figure>\n",
        "<center>\n",
        "<img src= 'https://drive.google.com/uc?id=1UfGo80-JtENJVHb4A89ZLJWzHIztDKCJ'/>\n",
        "</center>\n",
        "</figure>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qw8aTEPV1eKR",
        "colab_type": "text"
      },
      "source": [
        "#CONCLUSION\n",
        "In this project, the dataset of heart disease patient is investigated and analyzed. Data processing is performed to make the data ready for machine learning algorithm. Four different models were built, and it was found that K-nearest neighbor classifier yields the maximum score.\n",
        "1.\tK-nearest neighbors – 87%\n",
        "2.\tSVM – 83%\n",
        "3.\tDecision tree – 79%\n",
        "4.\tRandom forest – 84%\n",
        "More parameters changes could have been made and evaluated. Like in K-nearest neighbor, the tried value of k was from 1 to 20 only. Also, in SVM, only 4 kernels are tried. If this was done, then maximum score might have increased, and some other classifier may have yielded best result.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Msk2yNdY4tYl",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "# ETHICAL\n",
        "\n",
        "The use of machine learning to determine whether a person has a heart disease or not is nice was of helping the people who are unaware that they are already having or are on the verge of getting a heart disease. I would like to explain it through Deontological ethical approach.\n",
        "Deontological Ethics\n",
        "The principle it is based on are:\n",
        "1.\tArriving at ethical principles through reason\n",
        "2.\tReasons must clear and steady.\n",
        "3.\tDuty towards others based on these ethical principles\n",
        "4.\tOne of the primary values is respecting the autonomy of people.\n",
        "\n",
        "It is ethically correct to help people when you have the power to do so. When you can create such a technique, it’s your duty to do it. These ethics push us forward to research more and make this technique more efficient. Just informing a person that he or she might be at a risk of getting a heart disease falls under respecting people’s autonomy because they get a chance to self-govern themselves and make changes in their lives.\n",
        "Possible misuse of this technique: This technique could be misused by marketing companies or hospitals that are using data science to collect and analyze customer information. They can find out and target those people which are suffering from heart diseases. Making profit out of people’s misery is unethical and should not be done.\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "\n",
        "\n",
        "Github Link - https://github.com/Gurliv24/UTS_ML_13476256.git"
      ]
    }
  ]
}